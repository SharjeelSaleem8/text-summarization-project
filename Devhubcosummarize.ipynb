{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79b47c5-6ff3-4413-bcef-7dc24417cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import pipeline, BartForConditionalGeneration, BartTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c61e453a-6ffe-4854-8e60-bcc088239568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a34ec6e-7f40-4f49-acea-4feb24d4dbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc5f464-0a4d-46d7-9404-251b79c1f17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text;summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Guingamp defender Benjamin Angoua took an unorthodox method to try and stop his goalkeeper getting sent off. Stopper Mamadou Samassa was about to be given his marching order during the club's Ligue 1 clash against Montpellier for his furious protests after conceding a goal. But as referee Philippe Kalt was brandishing the red card</th>\n",
       "      <th>the Ivorian international knocked it out of the official's hand not once but twice. On the second attempt Angoua succeeded but after fumbling the card</th>\n",
       "      <td>Kalt dismissed Samassa. Angoua fortunately es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahead of another weekend of the Barclays Premier League</th>\n",
       "      <th>Sportsmail brings you the latest squad news</th>\n",
       "      <td>odds and stats on every top flight fixture as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Lorenzo will play Real Madrid in Saturday's FIFA World Club final after the Argentine side beat Auckland City 2-1 in extra time on Wednesday night. Pablo Barrientos fired San Lorenzo into the lead just before half time before Angel Berlanga equalised for Auckland City in the 67th minute. But</th>\n",
       "      <th>Mauro Matos pounced early on in the first half of extra time to put the Argentines ahead again. A place in the final against the Galacticos now awaits San Lorenzo with the finale due to take place on Saturday night in Morocco.;Pablo Barrientos scores for San Lorenzo just before the break . Angel Berlanga equalises for Auckland City in the second half . Mauro Matos strikes in extra time to give San Lorenzo 2-1 lead . San Lorenzo will play Real Madrid in Saturday's final. . Auckland beat Setif in quarter-finals</th>\n",
       "      <td>while Argentine side received a bye . Live st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angel di Maria has given his first interview as a Manchester United player following his £60million British transfer record switch from Real Madrid. The Argentina star has given United a boost during a troubled week in which they lost 4-0 to League One MK Dons. He has also been getting familiar with his new surroundings</th>\n",
       "      <th>being pictured out and about in Manchester this week. He - and the United fans - will hope he is in the squad to face Burnley on Saturday. Like our dedicated Manchester United Facebook page. Putting their shirt on him: Mancheter United's British record signing Angel di Maria VIDEO I will help United return to the top - Di Maria;Angel Di Maria joined Manchester United on Tuesday in a British transfer record smashing £60m move . The Argentina winger's arrival has given Man Utd a boost amid a poor start to the season . Di Maria has been unveiled today . Man United fans will hope to see him against Burnley on Saturday . Di Maria pictured out in Manchester this week . Click here to watch the interview on MUTV . For more news on United's summer signings click here</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hull's Ahmed Elmohamady has pulled out of Egypt's forthcoming African Nations Cup double header. Elmohamady, the right winger or full-back, was injured during a man-of-the-match performance against Crystal Palace at the weekend and will not be travelling for Friday's game in Botswana or the home clash in Cairo five days later. A short statement from the Tigers read: \"The club can confirm that Ahmed Elmohamady has withdrawn from Egypt's African Cup of Nations qualifiers with a back spasm.\" Ahmed Elmohamady tries to win the ball for Hull City during Saturday's 2-0 win on against Crystal Palace The Egyptian wing-back attempts to beat Gael Clichy during the Tigers' 4-2 defeat against Manchester City;Hull City's Ahmed Elmohamady is out of Egypt's African Cup of Nations two qualifiers this month due to back spasms . Egypt play Botswana on Friday then again next Wednesday . Elmohamady suffered the injury in Hull's 2-0 win against Crystal Palace . hull have not confirmed how long the player will be out for</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text;summary\n",
       "Guingamp defender Benjamin Angoua took an unort...  the Ivorian international knocked it out of th...   Kalt dismissed Samassa. Angoua fortunately es...\n",
       "Ahead of another weekend of the Barclays Premie...  Sportsmail brings you the latest squad news         odds and stats on every top flight fixture as...\n",
       "San Lorenzo will play Real Madrid in Saturday's...  Mauro Matos pounced early on in the first half...   while Argentine side received a bye . Live st...\n",
       "Angel di Maria has given his first interview as...  being pictured out and about in Manchester thi...                                                NaN\n",
       "Hull's Ahmed Elmohamady has pulled out of Egypt... NaN                                                                                               NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\data_all_raw_500.csv\", on_bad_lines='skip')\n",
    "  # Deprecated in newer pandas versions, use `on_bad_lines='skip'`\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e90fad5-2e25-4ee4-8c31-4addc2f75061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        text;summary\n",
      "0  Guingamp defender Benjamin Angoua took an unor...\n",
      "1  Ahead of another weekend of the Barclays Premi...\n",
      "2  By Jonathan Block Several pornographic images ...\n",
      "3  San Lorenzo will play Real Madrid in Saturday'...\n",
      "4  QPR midfielder Leroy Fer will be sidelined for...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\data_all_raw_500.csv\", sep=\"\\t\", on_bad_lines='skip')  # Try tab-separated\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0920336e-ba0f-4257-8524-8fc26b6d91bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Guingamp defender Benjamin Angoua took an unor...   \n",
      "1  Ahead of another weekend of the Barclays Premi...   \n",
      "2  By Jonathan Block Several pornographic images ...   \n",
      "3  San Lorenzo will play Real Madrid in Saturday'...   \n",
      "4  QPR midfielder Leroy Fer will be sidelined for...   \n",
      "\n",
      "                                             summary  \n",
      "0  Ivorian defender Benjamin Angoua nicked the re...  \n",
      "1  Table toppers Chelsea face a trip to Swansea o...  \n",
      "2  Sarah Bajc, girlfriend of passenger Philip Woo...  \n",
      "3  Pablo Barrientos scores for San Lorenzo just b...  \n",
      "4  QPR won for the first time away this season at...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\data_all_raw_500.csv\", sep=\";\", on_bad_lines='skip')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04453dd4-faa4-476f-8023-d1e4f12ed853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       0\n",
      "summary    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4dc8769-1a15-4503-a926-3f92f8cff9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b39e9f6-00aa-4bb5-b00e-005ea8e45673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())  # Count duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c812113-096e-4858-a5e8-691880cab756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc734320-bfb6-4489-b727-13456690a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(130, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())  # Should return 0\n",
    "print(df.shape)  # Rows should decrease if duplicates were present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b7d3b2-3bf5-4702-a2fb-6a5c0af1b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.7 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.7 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.5/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.7 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d09c586-5e78-41e8-91be-a77a832b0f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Guingamp defender Benjamin Angoua took an unor...   \n",
      "1  Ahead of another weekend of the Barclays Premi...   \n",
      "2  By Jonathan Block Several pornographic images ...   \n",
      "3  San Lorenzo will play Real Madrid in Saturday'...   \n",
      "4  QPR midfielder Leroy Fer will be sidelined for...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Ivorian defender Benjamin Angoua nicked the re...   \n",
      "1  Table toppers Chelsea face a trip to Swansea o...   \n",
      "2  Sarah Bajc, girlfriend of passenger Philip Woo...   \n",
      "3  Pablo Barrientos scores for San Lorenzo just b...   \n",
      "4  QPR won for the first time away this season at...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  guingamp defender benjamin angoua took unortho...  \n",
      "1  ahead another weekend barclays premier league ...  \n",
      "2  jonathan block several pornographic images uns...  \n",
      "3  san lorenzo play real madrid saturdays fifa wo...  \n",
      "4  qpr midfielder leroy fer sidelined ten weeks s...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "print(df.head())  # Check cleaned text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97714864-2f15-48b2-a1b4-3bfe062e3f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 104\n",
      "Testing Samples: 26\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, train_summaries, test_summaries = train_test_split(\n",
    "    df[\"cleaned_text\"], df[\"summary\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training Samples: {len(train_texts)}\")\n",
    "print(f\"Testing Samples: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3219a814-3c6b-4c6a-8174-db613598ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Guingamp defender Benjamin Angoua took an unor...   \n",
      "1  Ahead of another weekend of the Barclays Premi...   \n",
      "2  By Jonathan Block Several pornographic images ...   \n",
      "3  San Lorenzo will play Real Madrid in Saturday'...   \n",
      "4  QPR midfielder Leroy Fer will be sidelined for...   \n",
      "\n",
      "                                  extractive_summary  \n",
      "0  guingamp defender benjamin angoua took unortho...  \n",
      "1  ahead another weekend barclays premier league ...  \n",
      "2  jonathan block several pornographic images uns...  \n",
      "3  fifa world club final argentine side beat auck...  \n",
      "4  qpr midfielder leroy fer sidelined ten weeks s...  \n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def extractive_summary(text, num_sentences=3):\n",
    "    doc = nlp(text)\n",
    "    sentence_scores = {}\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text.lower() not in stop_words:\n",
    "                sentence_scores[sent] = sentence_scores.get(sent, 0) + 1\n",
    "    \n",
    "    summary_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    return \" \".join([sent.text for sent in summary_sentences])\n",
    "\n",
    "df[\"extractive_summary\"] = df[\"cleaned_text\"].apply(lambda x: extractive_summary(x, 3))\n",
    "\n",
    "print(df[[\"text\", \"extractive_summary\"]].head())  # Compare summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3921418-347a-48e3-8e59-0c2a10ec6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractive_summary(text, max_length=50, min_length=20):\n",
    "    if len(text.split()) > 512:  # Reduce input length\n",
    "        text = \" \".join(text.split()[:512])\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, min_length=min_length, length_penalty=2.0\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b05866a1-5b51-4467-a406-33e3781b5de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./models\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45faf32b-0c3b-4b2c-b3d6-14dd2d981a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c93ae0e6-a14d-41dc-950b-162ec3b80ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sumy in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sumy) (2.32.3)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sumy) (3.9.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\user\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ecc57aa-1698-458a-9608-e1e702c2e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0d2bb4-438e-4074-b02d-d4ae61c0fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"C:\\\\Users\\\\USER\\\\nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8809bae-fcf4-4ff7-88fa-3992cd67c7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c1db71b-4b76-4d2a-9595-30a2d2e02d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Your long paragraph goes here...\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    \n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Example usage\n",
    "text = \"Your long paragraph goes here...\"\n",
    "summary = summarize_text(text)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "487be36c-d0dd-4ed4-9fc8-b98db0e90cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Machine learning is a method of data analysis that automates analytical model building. Using algorithms that iteratively learn from data, machine learning allows computers to find hidden insights without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "def summarize_text(text, num_sentences=2):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    \n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\"Machine learning is a method of data analysis that automates analytical model building. \n",
    "Using algorithms that iteratively learn from data, machine learning allows computers to find hidden \n",
    "insights without being explicitly programmed. It is widely used in various applications such as \n",
    "image recognition, speech recognition, and medical diagnosis. The demand for AI and ML skills \n",
    "has increased significantly in the job market.\"\"\"\n",
    "summary = summarize_text(text, num_sentences=2)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e60e1a-94d7-4294-8a09-d9a19ae6d6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
